<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>joker&#39;s blog</title>
  
  <subtitle>joker</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-02-06T03:19:26.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>joker</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>memory</title>
    <link href="http://yoursite.com/2018/02/05/cognition-memory/"/>
    <id>http://yoursite.com/2018/02/05/cognition-memory/</id>
    <published>2018-02-05T08:56:46.000Z</published>
    <updated>2018-02-06T03:19:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>Memory in cognition, including information processing model: sensory, working, long term memory, encoding strategies, retrieval and memory reconstruction</p><a id="more"></a><h4 id="information-processing-model-sensory-working-and-long-term-memory"><a href="#information-processing-model-sensory-working-and-long-term-memory" class="headerlink" title="information processing model: sensory, working, and long term memory"></a>information processing model: sensory, working, and long term memory</h4><p>three stages:</p><ul><li>sensory memory: temporal register containing all the information your sensors are taking in<ul><li>iconic memory: what you see, last &lt;0.5 seconds</li><li>echoic memory: what you hear, last 3-4 seconds</li></ul></li><li>working memory: process the selected information</li><li>long term memory<ul><li>explicit: facts and events can clearly described<ul><li>semantic memory, think it as words, like what we write in an exam</li><li>episodic memory, is an event, like a birthday party</li></ul></li><li>implicit: can’t say it clearly<ul><li>procedural memory, like how to ride a bike</li><li>priming memory, previous experience influence your current interpretation of an event</li></ul></li></ul></li></ul><h4 id="encoding-strategies"><a href="#encoding-strategies" class="headerlink" title="encoding strategies"></a>encoding strategies</h4><ul><li><p>rote rehearsal</p><p>repeat something again and again</p><p>the least effective encoding, not get into long term memory</p></li><li><p>chunking</p><p>chunk things into categories however it make sense to you and retrievable</p></li><li><p>mnemonic devices</p><p>helps you link what you are trying to learn into previous existing easier to remember information</p><ul><li>images a vivid image of what we try to remember</li><li>pegword system to remember sequence in order</li><li>acronym: use a familiar word to help remember, e.g. “LSTM” for “long short term memory”</li></ul></li><li><p>self-referencing</p><p>link the information to you personally</p></li><li><p>spacing</p><p>spread out your study over time rather than learning them all in one session</p></li></ul><h4 id="retrieval-cues"><a href="#retrieval-cues" class="headerlink" title="retrieval cues"></a>retrieval cues</h4><p>When try to remember something, we are acting”retrieval”. A successful retrieval depends on the cue we use, which can link what represent around us to the thing we want to remember</p><ul><li>priming: what you previously are thinking about</li><li>context: the place you study, etc.</li><li>state: mode, etc.</li></ul><h4 id="retrieval-free-recall-cued-recall-and-recognition"><a href="#retrieval-free-recall-cued-recall-and-recognition" class="headerlink" title="retrieval: free recall, cued recall and recognition"></a>retrieval: free recall, cued recall and recognition</h4><ul><li><p>free recall</p><p>first listen to a series of item, then recall them freely, the result is usually in a pattern:</p><ul><li>primacy fact: people tend to remember the first few items</li><li>recency fact: people tend to remember the last few items</li><li>people tend to forget the items in the middle</li><li>this pattern is called “serial position” of fact</li></ul></li><li><p>cued recall</p><p>remember items given a cue</p></li><li><p>recognition</p><p>given several words, ask people which one they heard earlier, this is the task people do best</p></li></ul><h4 id="memory-reconstruction-source-monitoring-and-emotional-memories"><a href="#memory-reconstruction-source-monitoring-and-emotional-memories" class="headerlink" title="memory reconstruction, source monitoring and emotional memories"></a>memory reconstruction, source monitoring and emotional memories</h4><ul><li><p>memory reconstruction</p><p>Every time we retrieve a memory, we <strong>modify</strong> it slightly, this is called “reconstructive”</p><p><strong>false information</strong> told before retrieval can also lead to false memory</p><p><strong>misleading information</strong> also change people’s memory</p></li><li><p>source monitoring</p><p>Why false and misleading information can have a strong influence is that people have difficulty with the <strong>source memory</strong>, which is to keep track of where the information is came from. So people can’t tell whether the misleading information is from the original information.</p></li><li><p>flashbulb memories</p><ul><li>highly detailed, exceptionally vivid ‘snapshot’ of the moment and circumstances in which a piece of surprising and consequential (or emotionally arousing) news was heard(from wiki)</li><li>still susceptible to reconstruction</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Memory in cognition, including information processing model: sensory, working, long term memory, encoding strategies, retrieval and memory reconstruction&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Learn</title>
    <link href="http://yoursite.com/2018/02/05/cognition-learn/"/>
    <id>http://yoursite.com/2018/02/05/cognition-learn/</id>
    <published>2018-02-05T08:56:46.000Z</published>
    <updated>2018-02-06T03:15:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>Learning theory in cognition, including Piaget’s stages of cognitive development, problem solving, decision making, semantic networks, spreading activation, intelligence, aging and cognitive abilities</p><a id="more"></a><h4 id="Piaget’s-stages-of-cognitive-development"><a href="#Piaget’s-stages-of-cognitive-development" class="headerlink" title="Piaget’s stages of cognitive development"></a>Piaget’s stages of cognitive development</h4><p>Piaget’s four stages of cognitive development:</p><ul><li><p>0-2 years: sensorimotor stage</p><p>sensor: sensory comes from sensors</p><p>motor: they are very active</p><p>object permanence(say, if you take a ball away, the baby don’t know it still exists)</p></li><li><p>2-7 years: preoperational stage</p><p>start to pretend play, begin to able to use symbols to represent things</p></li><li><p>7-11 years: concrete operational stage</p><p>learn the idea of conservation(know the amount of water doesn’t change according to the shape of the glass)</p></li><li><p>12+ years: formal operational stage</p><p>able to reason abstract concepts, moral reasoning begin</p></li></ul><h4 id="Problem-solving"><a href="#Problem-solving" class="headerlink" title="Problem solving"></a>Problem solving</h4><p>categories of problem</p><ul><li>well-defined: clear start and ending point</li></ul><ul><li>ill-defined: more ambiguous start and ending point e.g. be happy</li></ul><p>methods of problem solving</p><ul><li><p>trial + error</p></li><li><p>algorithm</p></li><li><p>heuristics</p><ul><li><p>means-end analysis</p><p>we analyze the main problem and break it down to two smaller problems, then we attack the biggest sub-problem in order to reduce the most difference between our current state and the goal state</p></li><li><p>working backwards</p><p>start with goal state, and use it to suggest connections back to current state</p></li><li><p>insight</p><p>the solution just pops into your head, usually comes after a period of incubation.</p></li></ul></li></ul><h4 id="Decision-making"><a href="#Decision-making" class="headerlink" title="Decision making"></a>Decision making</h4><p>Decision making heuristics:</p><ul><li><p>availability heuristics: use examples readily come to mind or easily available in <strong>memory</strong></p></li><li><p>representativeness heuristics: judge the probability of an event based on our existing <strong>prototype</strong>, or general concept of what is typical</p><p>can lead to conjunction fallacy: people think cooccurence of two instances is more likely than a single one</p></li></ul><p>bias prevent us from making correct decisions or changing our decisions</p><ul><li>overconfidence</li><li>belief perseverance: ignore/rationalize disconfirming facts</li><li>confirmation bias: seek out only confirming facts</li></ul><p>framing effects</p><ul><li>framing: how to represent decision</li><li>put the problem in different ways(e.g. how many people will die $\leftrightarrow$ how many people will be saved), can change your decision</li></ul><h4 id="semantic-networks-and-spreading-activation"><a href="#semantic-networks-and-spreading-activation" class="headerlink" title="semantic networks and spreading activation"></a>semantic networks and spreading activation</h4><p>semantic networks</p><ul><li>concept are organized in one’s mind in terms of connected ideas</li></ul><p>modified semantic network</p><ul><li>every individual network based on their experience and knowledge, network can be different for different people</li></ul><p>spreading activation</p><p>when activate one concept, pull up related concepts along with it.</p><h4 id="Intelligence"><a href="#Intelligence" class="headerlink" title="Intelligence"></a>Intelligence</h4><p>three kind of intelligence:</p><ul><li>analytical intelligence</li><li>creative intelligence</li><li>practical intelligence</li></ul><p>Or, 2 categories of intelligence</p><ul><li><p>fluid intelligence</p><p>quick and abstract reasoning</p></li><li><p>crystallized intelligence</p><p>accumulated knowledge</p></li></ul><h4 id="Aging-and-cognitive-abilities"><a href="#Aging-and-cognitive-abilities" class="headerlink" title="Aging and cognitive abilities"></a>Aging and cognitive abilities</h4><p>aging and cognitive abilities:</p><ul><li>decline<ul><li>recall</li><li>episodic memory</li><li>processing speed</li><li>divided attention</li></ul></li><li>stable<ul><li>implicit memory stays the same, e.g. ride a bike</li><li>recognition memory, e.g. whether you are 27 or 67</li></ul></li></ul><ul><li>improve<ul><li>semantic memory</li><li>crystallized IQ</li><li>emotional reasoning</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Learning theory in cognition, including Piaget’s stages of cognitive development, problem solving, decision making, semantic networks, spreading activation, intelligence, aging and cognitive abilities&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>attention and language</title>
    <link href="http://yoursite.com/2018/02/05/cognition-attention%20and%20language/"/>
    <id>http://yoursite.com/2018/02/05/cognition-attention and language/</id>
    <published>2018-02-05T08:56:46.000Z</published>
    <updated>2018-02-06T03:17:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>Attention in cognition, including divided attention, selective attention, inattentional blindness, change blindness, theories of selective attention, theories of language and cognition and theories of language development.</p><a id="more"></a><h4 id="divided-attention-selective-attention-inattentional-blindness-amp-change-blindness"><a href="#divided-attention-selective-attention-inattentional-blindness-amp-change-blindness" class="headerlink" title="divided attention, selective attention, inattentional blindness &amp; change blindness"></a>divided attention, selective attention, inattentional blindness &amp; change blindness</h4><ul><li><p>divided attention</p><p>When we want to do things simultaneously, what we actually do is switching our attention between different tasks quickly.</p></li></ul><ul><li><p>selective attention</p><p>when we focus one thing at a time, we are exercising selective attention. At any moment, we choose an area we interested at to focus on, and everything else just be ignored.</p><ul><li><p>exogenous</p><p>we don’t have to tell ourselves to look at them, e.g. bright colors, loud noises</p></li><li><p>endogenous</p><p>have to understand it in the first place, then follow it. e.g. an arrow</p></li></ul></li><li><p>inattentional blindness</p><p>We are not consciously aware of things that happen in our visional filed when our attention is directed elsewhere in that filed.</p></li><li><p>change blindness</p><p>fail to notice the difference between a previous state and current state</p></li></ul><h4 id="theories-of-selective-attention"><a href="#theories-of-selective-attention" class="headerlink" title="theories of selective attention"></a>theories of selective attention</h4><ul><li><p>Broadbent’s early selection theory</p><p>all the information goes into one’s <strong>sensory register</strong>, which stores all the information we get. Then these get transferred to the <strong>selective filter</strong>. <strong>Perceptual process</strong> process the selected information to get its meaning.</p><p><img src="b.png" alt=""></p><p>flaw: cocktail party problem: if you filter before you know its meaning, then you shouldn’t identify people calling your name</p></li><li><p>Deutsch &amp; Deutsch’s late selection theory</p><p>Perceptual process happens before selective filter</p><p><img src="dd.png" alt=""></p><p>flaw: waste too much energy process all these information</p></li><li><p>Treismon’s attenuation theory</p><p>Instead of a complete selective filter, we have an <strong>attenuator</strong>: we still assign meaning to the unwanted information, but with a low priority.</p><p><img src="ta.png" alt=""></p></li></ul><h4 id="Theories-of-language-and-cognition"><a href="#Theories-of-language-and-cognition" class="headerlink" title="Theories of language and cognition"></a>Theories of language and cognition</h4><p>different theories of relations between language and thought:</p><ul><li>universalism: thought before language, and thought determines language completely</li><li>thought influence language(Piaget)</li><li>independent, but we learn to use them at the same time(Vygotsky)</li><li>linguistic determinism<ul><li>weak hypothesis: language influences thought</li><li>strong hypothesis: language determines thought completely, also called “Whorfian hypothesis”</li></ul></li></ul><h4 id="Theories-of-language-development-Nativist-learning-interactionist"><a href="#Theories-of-language-development-Nativist-learning-interactionist" class="headerlink" title="Theories of language development: Nativist, learning, interactionist"></a>Theories of language development: Nativist, learning, interactionist</h4><ul><li><p>nativist/innatist</p><p>children are born with the ability to learn language(Chomsky)</p></li><li><p>learning theory</p><p>children only acquire language through reinforcement</p></li><li><p>interactionist</p><p>biological and social factors have to interact to learn language(Vygotsky)</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Attention in cognition, including divided attention, selective attention, inattentional blindness, change blindness, theories of selective attention, theories of language and cognition and theories of language development.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Random Graphs</title>
    <link href="http://yoursite.com/2018/02/03/random%20graphs/"/>
    <id>http://yoursite.com/2018/02/03/random graphs/</id>
    <published>2018-02-02T16:54:42.000Z</published>
    <updated>2018-02-02T17:09:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>proporties of random graphs</p><a id="more"></a><p>$G_{n,p}$ is an $n$-vertex graph the existence of each of whose edges is independently determined by tossing a $p$-coin.</p><h4 id="generation"><a href="#generation" class="headerlink" title="generation"></a>generation</h4><p>Generated by stochastic processes:</p><ul><li>playing super dice</li><li>Erdos-Renyi model $G_{n,p}$ proposed by Gilbert</li><li>$G_{n, \frac{1}{2}}\sim G_n$, statistics, homogeneity</li><li>A spectrum of probability spaces on the same space</li></ul><h4 id="decoupling"><a href="#decoupling" class="headerlink" title="decoupling"></a>decoupling</h4><p>$G<em>{n,m}\sim G</em>{n,p}| (m \text{ edges exist})$</p><h4 id="isolated-vertices"><a href="#isolated-vertices" class="headerlink" title="isolated vertices"></a>isolated vertices</h4><p>In random graph $G_{n,m}$ with $m=\frac{n\ln n+cn}{2}$, the probability of existence of isolated vertices converges to $1-e^{-e^{-c}}$.</p><h4 id="Threshold-phenomena"><a href="#Threshold-phenomena" class="headerlink" title="Threshold phenomena"></a>Threshold phenomena</h4><p>Threshold functions:</p><p>Given $f(n)$ and event $E$, if $E$ does not happen on $G<em>{n,o(f)}$ with high probability but happens on $G</em>{n,w(f)}$ with high probability, $f(n)$ is a threshold function of $E$.</p><p>Sharp threshold functions:</p><p>Given $f(n)$ and event $E$, if $E$ does not happen on $G_{n,cf}$ with high probability for any $c<1$ but="" happens="" with="" high="" probability="" for="" any="" $c="">1$, $f(n)$ is a sharp threshold function of $E$.</1$></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;proporties of random graphs&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Method of Counting and Expectation</title>
    <link href="http://yoursite.com/2018/02/03/Method%20of%20counting%20and%20expectation/"/>
    <id>http://yoursite.com/2018/02/03/Method of counting and expectation/</id>
    <published>2018-02-02T16:54:41.000Z</published>
    <updated>2018-02-02T17:08:21.000Z</updated>
    
    <content type="html"><![CDATA[<p>probabilistic method of counting and expection, including counting argument, first-moment method, expectation argument, second-moment method and Lovasz local lemma</p><a id="more"></a><h4 id="Probabilistic-Method"><a href="#Probabilistic-Method" class="headerlink" title="Probabilistic Method"></a>Probabilistic Method</h4><p>Proving the existence of an object satisfying a certain property without constructing it.</p><p>Underlying principle:</p><p>probability space $\to$ nonzero probability $\to$ existence</p><h4 id="Main-Probabilistic-Methods"><a href="#Main-Probabilistic-Methods" class="headerlink" title="Main Probabilistic Methods"></a>Main Probabilistic Methods</h4><ul><li><p>counting argument</p><p>construct a probability space and calculate the probability</p><p>algorithm design: sampling</p></li><li><p>first-moment method</p><p>use the expectation in probabilistic reasoning</p><p>two types of first-moment method:</p><ul><li><p>expectation argument</p><p>$Pr(X\geq E[X])&gt;0, Pr(X \leq E[X])&gt;0$</p></li><li><p>Markov’s inequality for non-negative $X$</p><p>$Pr(X\geq a) \leq \frac{E[X]}{a}$</p></li></ul></li><li><p>second-moment method</p><p>Chebyshev inequation: $Pr(|X-E[X]|\geq a)\leq \frac{Var[X]}{a^2}$</p></li><li><p>Lovasz local lemma</p><p>Let $E_1, \dots, E_n$ be a set of events, and assume that the following hold:</p><ul><li>for all $i$, $Pr(E_i)\leq p$</li><li>the degree of the dependency graph given by $E_1, \dots, E_n$ is bounded by $d$</li><li>$4dp\leq 1$</li></ul><p>Then<br>$$<br>Pr\left(\cap_{i=1}^n \bar{E_i} \right)&gt;0<br>$$<br>​</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;probabilistic method of counting and expection, including counting argument, first-moment method, expectation argument, second-moment method and Lovasz local lemma&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Handling Dependency -- Bins and Balls</title>
    <link href="http://yoursite.com/2018/02/03/handling%20dependency/"/>
    <id>http://yoursite.com/2018/02/03/handling dependency/</id>
    <published>2018-02-02T16:54:41.000Z</published>
    <updated>2018-02-02T17:07:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>bins&amp;balls model, and how to handle dependency</p><a id="more"></a><h4 id="Bins-and-Balls"><a href="#Bins-and-Balls" class="headerlink" title="Bins and Balls"></a>Bins and Balls</h4><p>Put $m$ balls into $n$ bins randomly, denoted as $(m,n)$-model.</p><ul><li><p>basic properties</p><p>number of balls in any bin: $Bin(m, \frac{1}{n})$</p><p>numbers of balls in multiple bins: not independent.</p></li></ul><h4 id="Poisson-Approximation-Theorem"><a href="#Poisson-Approximation-Theorem" class="headerlink" title="Poisson Approximation Theorem"></a>Poisson Approximation Theorem</h4><p>$$<br>(X_1^{(m)}, X_2^{(m)}, \dots, X_n^{(m)}) \sim (Y_1^{(\mu)}, Y_2^{(\mu)}, \dots, Y_n^{(\mu)}| \sum_i^{(\mu)}=m)<br>$$</p><h4 id="Condition-free-Poisson-Approximation"><a href="#Condition-free-Poisson-Approximation" class="headerlink" title="Condition-free Poisson Approximation"></a>Condition-free Poisson Approximation</h4><p>$X_i^{m}$: the load of bin $i$ in $(m,n)$-model</p><p>$Y_i^{(m)}$: independent Poisson r.v.s with expectation $\frac{m}{n}$</p><p>For any non-negative $n$-ary fnction $f$, we have<br>$$<br>E[f(X_1^{(m)}, X_2^{(m)}, \dots, X_n^{(m)})] \leq\sqrt{m} E[f( (Y_1^{(m)}, Y_2^{(m)}, \dots, Y_n^{(m)})]<br>$$</p><h4 id="In-terms-of-probability…"><a href="#In-terms-of-probability…" class="headerlink" title="In terms of probability…"></a>In terms of probability…</h4><p>Any event that takes place with probability $p$ in the independent Poisson coupling takes places in Bins&amp;Balls setting with probability at most $pe\sqrt{m}$.</p><p>If the probability of an event in Bins&amp;Balls is monotonic in $m$, it is at most twice of that in the independent Poisson coupling.</p><h4 id="relation-between-Poisson-and-Normal-distribution"><a href="#relation-between-Poisson-and-Normal-distribution" class="headerlink" title="relation between Poisson and Normal distribution"></a>relation between Poisson and Normal distribution</h4><p>Should be related since both approximate binomial distribution.</p><p>When $\lambda \to \infty$, Poisson converges to Normal.</p><p>Specifically, $\lim<em>{\lambda \to \infty}\sum</em>{\alpha&lt;k&lt; \beta}\frac{\lambda^k e^{-\lambda}}{k!}=\frac{1}{\sqrt{2\pi}}\int_a^b e^{-\frac{x^2}{2}}dx$</p><p>where $a=(\alpha-\lambda)/\sqrt{\lambda}$, $b=(\beta-\lambda)/\sqrt{\lambda}$ are fixed.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;bins&amp;amp;balls model, and how to handle dependency&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Markov Chains</title>
    <link href="http://yoursite.com/2018/02/03/markov%20chains/"/>
    <id>http://yoursite.com/2018/02/03/markov chains/</id>
    <published>2018-02-02T16:54:41.000Z</published>
    <updated>2018-02-02T17:07:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>basic properties of markov chains</p><a id="more"></a><h4 id="Markov-Property"><a href="#Markov-Property" class="headerlink" title="Markov Property"></a>Markov Property</h4><p>$Pr(X<em>{n+1}=x</em>{n+1}|X_n=x_n,\dots,X_0=x<em>0)=Pr(X</em>{n+1}=x_{n+1}|X_n=x_n)$, for any $n\in N$ and $x_0, \dots, x_n \in S$.</p><p>The future is independent of the past, given the present state.</p><h4 id="Homogeneous"><a href="#Homogeneous" class="headerlink" title="Homogeneous"></a>Homogeneous</h4><p>$Pr(X_{n+1}=y|X<em>n=x)$ is independent of $n$, denoted by $p</em>{xy}$.</p><h4 id="Transition-Matrix"><a href="#Transition-Matrix" class="headerlink" title="Transition Matrix"></a>Transition Matrix</h4><p>$P=(p<em>{ij})</em>{i,j \in S}$, all entries are nonnegative, $\sum<em>j p</em>{ij}=1$</p><p>state distribution at time $t$:</p><p>Given initial distribution $\pi$, $\pi^{(t)}=\pi P^{(t)} = \pi P^t$</p><h4 id="Communicating-states"><a href="#Communicating-states" class="headerlink" title="Communicating states"></a>Communicating states</h4><p>$i\leftrightarrow j$, if $i \to j$ and $i \gets j$.</p><p>Equivalent conditions of reaching $j$ from $i$:</p><ul><li>There is a directed path in $G$ from $i$ to $j$</li><li>$p_{ij}^{(n)}&gt;0$ for some $n$.</li></ul><p>Denoted by $i \to j$.</p><h4 id="Period"><a href="#Period" class="headerlink" title="Period"></a>Period</h4><p>$p_{ii}^{(n)} &gt; 0$ only if $n$ is even. It is periodic.</p><p>$d_i$ is the GCD of $D<em>i\triangleq {n\geq 1: p</em>{ii}^{(n)} &gt; 0}$. If $d_i=1$, $i$ is said to be aperiodic.</p><p>Theorems:</p><ul><li>If $i \leftrightarrow j$, then $d_i = d_j$</li><li>If $i$ is aperiodic, $p_{ii}^{n}&gt;0$ for all large enough $n$</li></ul><h4 id="Hitting-time"><a href="#Hitting-time" class="headerlink" title="Hitting time"></a>Hitting time</h4><p>$T_{ij}$ is the first time that $j$ is reached when the initial state is $i$.</p><ul><li>$f_{ij}^{(t)} \triangleq Pr(X_t=j, X_k \neq j, 1 \leq k &lt; t | X<em>0 = i) = Pr(T</em>{ij} = t)$</li><li>$f_{ij} \triangleq \sum<em>t f</em>{ij}^{(t)}$</li></ul><h4 id="Recurrency"><a href="#Recurrency" class="headerlink" title="Recurrency"></a>Recurrency</h4><p>If $f_{ii}=1$, the state $i$ is recurrent(otherwise, transient)</p><ul><li>Furthermore, if $E[T_{ii}]&lt;\infty$, $i$ is positive recurrent</li><li>Otherwise, it is null recurrent</li></ul><h4 id="Theorem-of-recurrency"><a href="#Theorem-of-recurrency" class="headerlink" title="Theorem of recurrency"></a>Theorem of recurrency</h4><p>The following conditions are equivalent:</p><ul><li>$i$ is recurrent</li><li>$\sum<em>n p</em>{ii}^{(n)} = \infty$</li><li>$E[J_i|X_0=i]=\infty$, $J_i$ is the number of times $i$ is reached</li><li>$Pr(J_i=\infty| X_0=i)=1$</li></ul><p>Recurrency is preserved by communicating relation:</p><p>If $i\leftrightarrow j$ and $i$ is recurrent, then so is $j$.</p><h4 id="necessary-condition-of-transient-states"><a href="#necessary-condition-of-transient-states" class="headerlink" title="necessary condition of transient states"></a>necessary condition of transient states</h4><p>If $j$ is a transient, $\sum<em>{n=1}^{\infty}p</em>{ij}^{(n)} &lt; \infty$ for any $i$.</p><h4 id="stopping-time"><a href="#stopping-time" class="headerlink" title="stopping time"></a>stopping time</h4><p>A stopping time of Markov chain ${X<em>i}</em>{i\geq 0}$:</p><ul><li><p>A random variable $\tau \in Z_+ \cup \left{\infty\right}$ s.t.</p><p>$1(\tau=n)$ is a deterministic function of $X_0, \dots, X_n$</p></li></ul><h4 id="Strong-Markov-Property"><a href="#Strong-Markov-Property" class="headerlink" title="Strong Markov Property"></a>Strong Markov Property</h4><p>$\tau$ is a stopping time of homogeneous Markov chain ${X_t: t \geq 0}$.</p><p>$Pr(X_{\tau+t}=j<em>t, t\geq 1 | \tau &lt; \infty, X</em>{\tau-t}=i_t, 0\leq t \leq \tau)$</p><p>$=Pr(X_{\tau+t}=j<em>t, t \geq 1 | \tau &lt; \infty, X</em>{\tau}=i_0)$</p><p>$=Pr(X_t=j_t, t\geq 1| X_0=i_0)$</p><h4 id="Excursion"><a href="#Excursion" class="headerlink" title="Excursion"></a>Excursion</h4><p>Excursions: independent structure in Markov chains</p><p>Excursions are i.i.d. random variables:</p><ul><li>$\chi^{r}, r\geq0$ , are independent</li><li>$\chi^{r}, r\geq1$, have the same distribution</li></ul><h4 id="Stationary-Distribution"><a href="#Stationary-Distribution" class="headerlink" title="Stationary Distribution"></a>Stationary Distribution</h4><p>A distribution $\pi$ over $S$ satisfying $\pi P=\pi$ is a stationary distribution of the Markov chain.</p><p>existence theorem of stationary distribution:</p><p>If the Markov chain has a positive recurrent state $a$, $\pi^{[a]}\triangleq \frac{\nu ^{[a]}}{E[T_{aa}]} is a stationary distribution.</p><h4 id="Uniqueness-Theory"><a href="#Uniqueness-Theory" class="headerlink" title="Uniqueness Theory"></a>Uniqueness Theory</h4><p>For an irreducible Markov chain, its stationary distribution is unique if existent.</p><h4 id="Expected-return-time"><a href="#Expected-return-time" class="headerlink" title="Expected return time"></a>Expected return time</h4><p>Let $\pi$ be the stationary distribution of a irreducible, positive recurrent Markov chain. For all $a\in S$, $\pi(a)=\frac{1}{E[T_{aa}]}$.</p><h4 id="Stability-theorem-Theorem-of-limiting-probabilities"><a href="#Stability-theorem-Theorem-of-limiting-probabilities" class="headerlink" title="Stability theorem(Theorem of limiting probabilities)"></a>Stability theorem(Theorem of limiting probabilities)</h4><p>Let $\pi$ be the stationary distribution of an aperiodic, irreducible, and positive recurrent Markov chain. Then </p><ul><li>$\lim_{n\to \infty} Pr(X_n=i)=\pi(i)$ for any initial distribution and $i\in S$</li><li>$\lim<em>{n\to \infty}p</em>{ji}^{(n)}=\pi(i)$ for any $i,j \in S$.</li></ul><p>And the convergence are uniform with respect to $i$.</p><h4 id="Coupling-Lemma"><a href="#Coupling-Lemma" class="headerlink" title="Coupling Lemma"></a>Coupling Lemma</h4><p>$\lim<em>{n\to \infty}\sup</em>{i \in S} |Pr(X_n=i)-Pr(Y_n=i)|=0$</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;basic properties of markov chains&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Moments and Inequalities</title>
    <link href="http://yoursite.com/2018/02/03/moments%20and%20inequalities/"/>
    <id>http://yoursite.com/2018/02/03/moments and inequalities/</id>
    <published>2018-02-02T16:54:41.000Z</published>
    <updated>2018-02-02T17:09:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>moments, and inequalities including Markov’s Inequality, Chebyshev’s Inequality and Chernoff bounds</p><a id="more"></a><h3 id="Moments-of-random-variables"><a href="#Moments-of-random-variables" class="headerlink" title="Moments of random variables"></a>Moments of random variables</h3><p>$k$-th moment: $E[X^k]$</p><h4 id="Moment-generation-functions"><a href="#Moment-generation-functions" class="headerlink" title="Moment generation functions"></a>Moment generation functions</h4><p>$M<em>X(t)\triangleq \sum</em>{x} e^{tx} Pr(X=x)=E[e^{tX}]$</p><h4 id="Markov’s-Inequality"><a href="#Markov’s-Inequality" class="headerlink" title="Markov’s Inequality"></a>Markov’s Inequality</h4><p>If $X\geq 0$ and $a&gt;0$, $Pr(X\geq a) \leq \frac{E[X]}{a}$.</p><h4 id="Chebyshev’s-Inequality"><a href="#Chebyshev’s-Inequality" class="headerlink" title="Chebyshev’s Inequality"></a>Chebyshev’s Inequality</h4><p>$Pr(|X-E[X]|\geq a) \leq \frac{Var[X]}{a^2}$.</p><h4 id="Chernoff-bounds"><a href="#Chernoff-bounds" class="headerlink" title="Chernoff bounds"></a>Chernoff bounds</h4><p>Let $X=\sum_{i=1}^n X_i$, where $X_i$’s are independent Poisson trials. Let $\mu=E[X]$. Then</p><ol><li><p>For any $\delta &gt; 0$, $Pr(X\geq (1+\delta)\mu) \leq \left(\frac{e^{\delta}}{(1+\delta)^{(1+\delta)}}\right)^{\mu}$</p></li><li><p>For any  $1&gt;\delta &gt; 0$, $Pr(X\leq (1-\delta)\mu) \leq \left(\frac{e^{-\delta}}{(1-\delta)^{(1-\delta)}}\right)^{\mu}$</p><p>​</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;moments, and inequalities including Markov’s Inequality, Chebyshev’s Inequality and Chernoff bounds&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Elementary Probability Theory</title>
    <link href="http://yoursite.com/2018/02/03/elementary%20probability%20theory/"/>
    <id>http://yoursite.com/2018/02/03/elementary probability theory/</id>
    <published>2018-02-02T16:54:40.000Z</published>
    <updated>2018-02-02T17:05:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>basic laws of probability, including union bound, bayes’s law, etc.<br><a id="more"></a></p><h4 id="union-bound"><a href="#union-bound" class="headerlink" title="union bound"></a>union bound</h4><p>$$<br>Pr(\cup_{i\geq1}E<em>i) \leq \sum</em>{i\geq1}Pr(E_i)<br>$$</p><h4 id="Law-of-total-probability"><a href="#Law-of-total-probability" class="headerlink" title="Law of total probability"></a>Law of total probability</h4><p>If $E_1, E_2, \dots E<em>n$ are mutually disjoint and $\cup</em>{i=1}^nE<em>i=\Omega$, then $Pr(B)=\sum</em>{i=1}^nPr(B\cap E<em>i)=\sum</em>{i=1}^n Pr(B|E_i)Pr(E_i)$.</p><h4 id="Bayes’-Law"><a href="#Bayes’-Law" class="headerlink" title="Bayes’ Law"></a>Bayes’ Law</h4><p>If $E_1, E_2, \dots E<em>n$ are mutually disjoint and $\cup</em>{i=1}^nE_i=\Omega$, then $Pr(E_j|B)=\frac{Pr(B|E_j)Pr(E_j)}{Pr(B)}=\frac{Pr(B|E_j)Pr(E<em>j)}{\sum</em>{i=1}^n Pr(B|E_i)Pr(E_i)}$.</p><h4 id="Expectation"><a href="#Expectation" class="headerlink" title="Expectation"></a>Expectation</h4><ul><li><p>Linearity of expectation<br>$$<br>E[\sum_{i=1}^na_iX<em>i]=\sum</em>{i=1}^n a_iE[X_i]<br>$$</p></li><li><p>product counterpart</p><p>$E[X* Y]=E[X]E[Y] $ if they are independent​​</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;basic laws of probability, including union bound, bayes’s law, etc.&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Fundamental Laws of Probability Theory</title>
    <link href="http://yoursite.com/2018/02/03/fundamental%20laws/"/>
    <id>http://yoursite.com/2018/02/03/fundamental laws/</id>
    <published>2018-02-02T16:54:40.000Z</published>
    <updated>2018-02-02T17:05:34.000Z</updated>
    
    <content type="html"><![CDATA[<p>Fundamental laws of probability theory, includes law of large numbers, central limit theorem, etc.</p><a id="more"></a><h4 id="Law-of-Large-Numbers"><a href="#Law-of-Large-Numbers" class="headerlink" title="Law of Large Numbers"></a>Law of Large Numbers</h4><p>The sample average converges to the expected value.</p><h4 id="Central-Limit-Theorem"><a href="#Central-Limit-Theorem" class="headerlink" title="Central Limit Theorem"></a>Central Limit Theorem</h4><p>The arithmetic mean of independent random variables is approximately normally distributed.</p><h4 id="Large-Deviation-Principle"><a href="#Large-Deviation-Principle" class="headerlink" title="Large Deviation Principle"></a>Large Deviation Principle</h4><p>Let $X_1, \dots, X_n, \dots \in R$ be i.i.d, r.v. which satisfy $E[e^{tX_1}]&lt;\infty$ for $t\in R$. Then for any $t&gt;E[X<em>1]$, we have<br>$$<br>\lim</em>{n\to \infty}\frac{1}{n}\ln Pr(\sum_{i=1}^nX<em>i \geq tn) = -I(t)<br>$$<br>where<br>$$<br>I(t) \triangleq \sup</em>{\lambda&gt;0} \lambda t - \ln E[e^{\lambda X_1}]<br>$$</p><h4 id="Law-of-large-number-in-Markov-chains"><a href="#Law-of-large-number-in-Markov-chains" class="headerlink" title="Law of large number in Markov chains"></a>Law of large number in Markov chains</h4><p>Assume Markov chain $\left{ X_n \right}$ has a positive recurrent state $a$, $Pr(a \text{ is reached}| X<em>0=1)$, and $f: S \to R$  is bounded. Then<br>$$<br>Pr\left(\lim</em>{t \to \infty} \frac{f(X_0) + \dots + f(X<em>t)}{t}=\bar{f}\right)=1<br>$$<br>where<br>$$<br>\bar{f}=\frac{E[\sum</em>{n=0}^{T_{aa}-1}f(X<em>n)]}{E[T</em>{aa}]}=E_{\pi}[f]<br>$$</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Fundamental laws of probability theory, includes law of large numbers, central limit theorem, etc.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>TranH</title>
    <link href="http://yoursite.com/2018/01/30/TransH/"/>
    <id>http://yoursite.com/2018/01/30/TransH/</id>
    <published>2018-01-30T12:12:44.000Z</published>
    <updated>2018-01-30T17:35:44.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>TransE - the cornerstone of translation approaches</title>
    <link href="http://yoursite.com/2018/01/30/TransE/"/>
    <id>http://yoursite.com/2018/01/30/TransE/</id>
    <published>2018-01-30T07:31:35.000Z</published>
    <updated>2018-01-30T17:53:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>TransE model proposed by Bordes et al. 提出了今后一系列translation方法的根基：</p><p>The functional relation induced by the $r$-labeled edges corresponds to a translation of the embeddings, i.e. $h + r \approx t$ when $(h, r, t)$ holds.</p><a id="more"></a><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>In TransE, relationships are represented as translations in the embedding space:</p><p>if $(h, r, t)$ holds, then the embedding of the tail entity $t$ should be close to the embedding of the head entity $h$ plus some vector that depends on the relationship $r$, which is<br>$$<br>h + r \approx t<br>$$<br>TransE maps all the entities and relations into the same embedding space, and learns only one low-dimensional vector for each of them.</p><h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><p>The functional relation induced by the $r$-labeled edges corresponds to a translation of the embeddings, i.e. $h + r \approx t$ when $(h, r, t)$ holds, while $h+r$ should be far away from $t$ otherwise.</p><p>The <strong>energy</strong> of a triplet is set to be $d(h+r, t)$ for some dissimilarity measure $d$, which is $L_1$ or $L_2$-norm.</p><p>Following an energy-based framework, the <strong>goal</strong> of TransE is to minimize a margin-based ranking criterion over the training set:<br>$$<br>L=\sum<em>{(h,r,t)\in S}\sum</em>{(h’,r,t’)\in S’<em>{(h,r,t)}}[\gamma + d(h+r, t) - d(h’+r, t’)]</em>{+}<br>$$<br>where $[x]<em>{+}$ denotes the positive part of $x$, which can also be denoted as $max(0, x)$. This can force $x$ to try to be as near $0$ as possible. $\gamma&gt;0$ is a margin hyperparameter, $S’$ is the set of corrupted triplets, constructed by replacing either head or tail entity by a random one:<br>$$<br>S’</em>{(h, r, t)} = \left{(h’, r, t) | h’ \in E \right} \cup \left{(h, r, t’)|t’\in E \right}<br>$$<br>The optimization is carried out by <strong>SGD</strong>, and the <strong>additional constraints</strong> that the $L_2$-norm of the embeddings of the entities is $1$, while no regularization or norm constraints are given to the label embeddings $r$. </p><p>The algorithm is stopped based on its performance on a validation set.</p><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>TransE can be implemented according to the algorithm:</p><p><img src="TransEAlg.png" alt="alg"></p><p>Note:</p><ul><li>relation $r$ is denoted as $l$ in the above algorithm</li><li>$l$ is normalized in the initialization stage, while the embedding vectors of the entities are first normalized at each main iteration</li><li>For each triplet in minibatch, sample a single corrupted triplet from $S’$. Golden triplets and corrupted triplets together consist triplet batch</li><li>Train to minimize $L$</li><li>$[x]_{+}$ is implemented by $max(0, x)$</li></ul><p>My implementation of TransE in tensorflow can be found on:</p><p><a href="http://baidu.com" target="_blank" rel="noopener">TransE implementation in tensorflow</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;TransE model proposed by Bordes et al. 提出了今后一系列translation方法的根基：&lt;/p&gt;
&lt;p&gt;The functional relation induced by the $r$-labeled edges corresponds to a translation of the embeddings, i.e. $h + r \approx t$ when $(h, r, t)$ holds.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
