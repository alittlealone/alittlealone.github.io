<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>joker&#39;s blog</title>
  
  <subtitle>joker</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-02-02T17:01:19.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>joker</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/03/random%20graphs/"/>
    <id>http://yoursite.com/2018/02/03/random graphs/</id>
    <published>2018-02-02T16:54:42.000Z</published>
    <updated>2018-02-02T17:01:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>title: Random Graphs</p><a id="more"></a><p>$G_{n,p}$ is an $n$-vertex graph the existence of each of whose edges is independently determined by tossing a $p$-coin.</p><h4 id="generation"><a href="#generation" class="headerlink" title="generation"></a>generation</h4><p>Generated by stochastic processes:</p><ul><li>playing super dice</li><li>Erdos-Renyi model $G_{n,p}$ proposed by Gilbert</li><li>$G_{n, \frac{1}{2}}\sim G_n$, statistics, homogeneity</li><li>A spectrum of probability spaces on the same space</li></ul><h4 id="decoupling"><a href="#decoupling" class="headerlink" title="decoupling"></a>decoupling</h4><p>$G<em>{n,m}\sim G</em>{n,p}| (m \text{ edges exist})$</p><h4 id="isolated-vertices"><a href="#isolated-vertices" class="headerlink" title="isolated vertices"></a>isolated vertices</h4><p>In random graph $G_{n,m}$ with $m=\frac{n\ln n+cn}{2}$, the probability of existence of isolated vertices converges to $1-e^{-e^{-c}}$.</p><h4 id="Threshold-phenomena"><a href="#Threshold-phenomena" class="headerlink" title="Threshold phenomena"></a>Threshold phenomena</h4><p>Threshold functions:</p><p>Given $f(n)$ and event $E$, if $E$ does not happen on $G<em>{n,o(f)}$ with high probability but happens on $G</em>{n,w(f)}$ with high probability, $f(n)$ is a threshold function of $E$.</p><p>Sharp threshold functions:</p><p>Given $f(n)$ and event $E$, if $E$ does not happen on $G_{n,cf}$ with high probability for any $c<1$ but="" happens="" with="" high="" probability="" for="" any="" $c="">1$, $f(n)$ is a sharp threshold function of $E$.</1$></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;title: Random Graphs&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/03/Method%20of%20counting%20and%20expectation/"/>
    <id>http://yoursite.com/2018/02/03/Method of counting and expectation/</id>
    <published>2018-02-02T16:54:41.000Z</published>
    <updated>2018-02-02T17:01:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>title: Method of Counting and Expectation</p><a id="more"></a><h4 id="Probabilistic-Method"><a href="#Probabilistic-Method" class="headerlink" title="Probabilistic Method"></a>Probabilistic Method</h4><p>Proving the existence of an object satisfying a certain property without constructing it.</p><p>Underlying principle:</p><p>probability space $\to$ nonzero probability $\to$ existence</p><h4 id="Main-Probabilistic-Methods"><a href="#Main-Probabilistic-Methods" class="headerlink" title="Main Probabilistic Methods"></a>Main Probabilistic Methods</h4><ul><li><p>counting argument</p><p>construct a probability space and calculate the probability</p><p>algorithm design: sampling</p></li><li><p>first-moment method</p><p>use the expectation in probabilistic reasoning</p><p>two types of first-moment method:</p><ul><li><p>expectation argument</p><p>$Pr(X\geq E[X])&gt;0, Pr(X \leq E[X])&gt;0$</p></li><li><p>Markov’s inequality for non-negative $X$</p><p>$Pr(X\geq a) \leq \frac{E[X]}{a}$</p></li></ul></li><li><p>second-moment method</p><p>Chebyshev inequation: $Pr(|X-E[X]|\geq a)\leq \frac{Var[X]}{a^2}$</p></li><li><p>Lovasz local lemma</p><p>Let $E_1, \dots, E_n$ be a set of events, and assume that the following hold:</p><ul><li>for all $i$, $Pr(E_i)\leq p$</li><li>the degree of the dependency graph given by $E_1, \dots, E_n$ is bounded by $d$</li><li>$4dp\leq 1$</li></ul><p>Then<br>$$<br>Pr\left(\cap_{i=1}^n \bar{E_i} \right)&gt;0<br>$$<br>​</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;title: Method of Counting and Expectation&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/03/handling%20dependency/"/>
    <id>http://yoursite.com/2018/02/03/handling dependency/</id>
    <published>2018-02-02T16:54:41.000Z</published>
    <updated>2018-02-02T17:00:57.000Z</updated>
    
    <content type="html"><![CDATA[<p>title: Handling Dependency – Bins and Balls</p><a id="more"></a><h4 id="Bins-and-Balls"><a href="#Bins-and-Balls" class="headerlink" title="Bins and Balls"></a>Bins and Balls</h4><p>Put $m$ balls into $n$ bins randomly, denoted as $(m,n)$-model.</p><ul><li><p>basic properties</p><p>number of balls in any bin: $Bin(m, \frac{1}{n})$</p><p>numbers of balls in multiple bins: not independent.</p></li></ul><h4 id="Poisson-Approximation-Theorem"><a href="#Poisson-Approximation-Theorem" class="headerlink" title="Poisson Approximation Theorem"></a>Poisson Approximation Theorem</h4><p>$$<br>(X_1^{(m)}, X_2^{(m)}, \dots, X_n^{(m)}) \sim (Y_1^{(\mu)}, Y_2^{(\mu)}, \dots, Y_n^{(\mu)}| \sum_i^{(\mu)}=m)<br>$$</p><h4 id="Condition-free-Poisson-Approximation"><a href="#Condition-free-Poisson-Approximation" class="headerlink" title="Condition-free Poisson Approximation"></a>Condition-free Poisson Approximation</h4><p>$X_i^{m}$: the load of bin $i$ in $(m,n)$-model</p><p>$Y_i^{(m)}$: independent Poisson r.v.s with expectation $\frac{m}{n}$</p><p>For any non-negative $n$-ary fnction $f$, we have<br>$$<br>E[f(X_1^{(m)}, X_2^{(m)}, \dots, X_n^{(m)})] \leq\sqrt{m} E[f( (Y_1^{(m)}, Y_2^{(m)}, \dots, Y_n^{(m)})]<br>$$</p><h4 id="In-terms-of-probability…"><a href="#In-terms-of-probability…" class="headerlink" title="In terms of probability…"></a>In terms of probability…</h4><p>Any event that takes place with probability $p$ in the independent Poisson coupling takes places in Bins&amp;Balls setting with probability at most $pe\sqrt{m}$.</p><p>If the probability of an event in Bins&amp;Balls is monotonic in $m$, it is at most twice of that in the independent Poisson coupling.</p><h4 id="relation-between-Poisson-and-Normal-distribution"><a href="#relation-between-Poisson-and-Normal-distribution" class="headerlink" title="relation between Poisson and Normal distribution"></a>relation between Poisson and Normal distribution</h4><p>Should be related since both approximate binomial distribution.</p><p>When $\lambda \to \infty$, Poisson converges to Normal.</p><p>Specifically, $\lim<em>{\lambda \to \infty}\sum</em>{\alpha&lt;k&lt; \beta}\frac{\lambda^k e^{-\lambda}}{k!}=\frac{1}{\sqrt{2\pi}}\int_a^b e^{-\frac{x^2}{2}}dx$</p><p>where $a=(\alpha-\lambda)/\sqrt{\lambda}$, $b=(\beta-\lambda)/\sqrt{\lambda}$ are fixed.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;title: Handling Dependency – Bins and Balls&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/03/markov%20chains/"/>
    <id>http://yoursite.com/2018/02/03/markov chains/</id>
    <published>2018-02-02T16:54:41.000Z</published>
    <updated>2018-02-02T17:01:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>title: Markov Chains</p><a id="more"></a><h4 id="Markov-Property"><a href="#Markov-Property" class="headerlink" title="Markov Property"></a>Markov Property</h4><p>$Pr(X<em>{n+1}=x</em>{n+1}|X_n=x_n,\dots,X_0=x<em>0)=Pr(X</em>{n+1}=x_{n+1}|X_n=x_n)$, for any $n\in N$ and $x_0, \dots, x_n \in S$.</p><p>The future is independent of the past, given the present state.</p><h4 id="Homogeneous"><a href="#Homogeneous" class="headerlink" title="Homogeneous"></a>Homogeneous</h4><p>$Pr(X_{n+1}=y|X<em>n=x)$ is independent of $n$, denoted by $p</em>{xy}$.</p><h4 id="Transition-Matrix"><a href="#Transition-Matrix" class="headerlink" title="Transition Matrix"></a>Transition Matrix</h4><p>$P=(p<em>{ij})</em>{i,j \in S}$, all entries are nonnegative, $\sum<em>j p</em>{ij}=1$</p><p>state distribution at time $t$:</p><p>Given initial distribution $\pi$, $\pi^{(t)}=\pi P^{(t)} = \pi P^t$</p><h4 id="Communicating-states"><a href="#Communicating-states" class="headerlink" title="Communicating states"></a>Communicating states</h4><p>$i\leftrightarrow j$, if $i \to j$ and $i \gets j$.</p><p>Equivalent conditions of reaching $j$ from $i$:</p><ul><li>There is a directed path in $G$ from $i$ to $j$</li><li>$p_{ij}^{(n)}&gt;0$ for some $n$.</li></ul><p>Denoted by $i \to j$.</p><h4 id="Period"><a href="#Period" class="headerlink" title="Period"></a>Period</h4><p>$p_{ii}^{(n)} &gt; 0$ only if $n$ is even. It is periodic.</p><p>$d_i$ is the GCD of $D<em>i\triangleq {n\geq 1: p</em>{ii}^{(n)} &gt; 0}$. If $d_i=1$, $i$ is said to be aperiodic.</p><p>Theorems:</p><ul><li>If $i \leftrightarrow j$, then $d_i = d_j$</li><li>If $i$ is aperiodic, $p_{ii}^{n}&gt;0$ for all large enough $n$</li></ul><h4 id="Hitting-time"><a href="#Hitting-time" class="headerlink" title="Hitting time"></a>Hitting time</h4><p>$T_{ij}$ is the first time that $j$ is reached when the initial state is $i$.</p><ul><li>$f_{ij}^{(t)} \triangleq Pr(X_t=j, X_k \neq j, 1 \leq k &lt; t | X<em>0 = i) = Pr(T</em>{ij} = t)$</li><li>$f_{ij} \triangleq \sum<em>t f</em>{ij}^{(t)}$</li></ul><h4 id="Recurrency"><a href="#Recurrency" class="headerlink" title="Recurrency"></a>Recurrency</h4><p>If $f_{ii}=1$, the state $i$ is recurrent(otherwise, transient)</p><ul><li>Furthermore, if $E[T_{ii}]&lt;\infty$, $i$ is positive recurrent</li><li>Otherwise, it is null recurrent</li></ul><h4 id="Theorem-of-recurrency"><a href="#Theorem-of-recurrency" class="headerlink" title="Theorem of recurrency"></a>Theorem of recurrency</h4><p>The following conditions are equivalent:</p><ul><li>$i$ is recurrent</li><li>$\sum<em>n p</em>{ii}^{(n)} = \infty$</li><li>$E[J_i|X_0=i]=\infty$, $J_i$ is the number of times $i$ is reached</li><li>$Pr(J_i=\infty| X_0=i)=1$</li></ul><p>Recurrency is preserved by communicating relation:</p><p>If $i\leftrightarrow j$ and $i$ is recurrent, then so is $j$.</p><h4 id="necessary-condition-of-transient-states"><a href="#necessary-condition-of-transient-states" class="headerlink" title="necessary condition of transient states"></a>necessary condition of transient states</h4><p>If $j$ is a transient, $\sum<em>{n=1}^{\infty}p</em>{ij}^{(n)} &lt; \infty$ for any $i$.</p><h4 id="stopping-time"><a href="#stopping-time" class="headerlink" title="stopping time"></a>stopping time</h4><p>A stopping time of Markov chain ${X<em>i}</em>{i\geq 0}$:</p><ul><li><p>A random variable $\tau \in Z_+ \cup \left{\infty\right}$ s.t.</p><p>$1(\tau=n)$ is a deterministic function of $X_0, \dots, X_n$</p></li></ul><h4 id="Strong-Markov-Property"><a href="#Strong-Markov-Property" class="headerlink" title="Strong Markov Property"></a>Strong Markov Property</h4><p>$\tau$ is a stopping time of homogeneous Markov chain ${X_t: t \geq 0}$.</p><p>$Pr(X_{\tau+t}=j<em>t, t\geq 1 | \tau &lt; \infty, X</em>{\tau-t}=i_t, 0\leq t \leq \tau)$</p><p>$=Pr(X_{\tau+t}=j<em>t, t \geq 1 | \tau &lt; \infty, X</em>{\tau}=i_0)$</p><p>$=Pr(X_t=j_t, t\geq 1| X_0=i_0)$</p><h4 id="Excursion"><a href="#Excursion" class="headerlink" title="Excursion"></a>Excursion</h4><p>Excursions: independent structure in Markov chains</p><p>Excursions are i.i.d. random variables:</p><ul><li>$\chi^{r}, r\geq0$ , are independent</li><li>$\chi^{r}, r\geq1$, have the same distribution</li></ul><h4 id="Stationary-Distribution"><a href="#Stationary-Distribution" class="headerlink" title="Stationary Distribution"></a>Stationary Distribution</h4><p>A distribution $\pi$ over $S$ satisfying $\pi P=\pi$ is a stationary distribution of the Markov chain.</p><p>existence theorem of stationary distribution:</p><p>If the Markov chain has a positive recurrent state $a$, $\pi^{[a]}\triangleq \frac{\nu ^{[a]}}{E[T_{aa}]} is a stationary distribution.</p><h4 id="Uniqueness-Theory"><a href="#Uniqueness-Theory" class="headerlink" title="Uniqueness Theory"></a>Uniqueness Theory</h4><p>For an irreducible Markov chain, its stationary distribution is unique if existent.</p><h4 id="Expected-return-time"><a href="#Expected-return-time" class="headerlink" title="Expected return time"></a>Expected return time</h4><p>Let $\pi$ be the stationary distribution of a irreducible, positive recurrent Markov chain. For all $a\in S$, $\pi(a)=\frac{1}{E[T_{aa}]}$.</p><h4 id="Stability-theorem-Theorem-of-limiting-probabilities"><a href="#Stability-theorem-Theorem-of-limiting-probabilities" class="headerlink" title="Stability theorem(Theorem of limiting probabilities)"></a>Stability theorem(Theorem of limiting probabilities)</h4><p>Let $\pi$ be the stationary distribution of an aperiodic, irreducible, and positive recurrent Markov chain. Then </p><ul><li>$\lim_{n\to \infty} Pr(X_n=i)=\pi(i)$ for any initial distribution and $i\in S$</li><li>$\lim<em>{n\to \infty}p</em>{ji}^{(n)}=\pi(i)$ for any $i,j \in S$.</li></ul><p>And the convergence are uniform with respect to $i$.</p><h4 id="Coupling-Lemma"><a href="#Coupling-Lemma" class="headerlink" title="Coupling Lemma"></a>Coupling Lemma</h4><p>$\lim<em>{n\to \infty}\sup</em>{i \in S} |Pr(X_n=i)-Pr(Y_n=i)|=0$</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;title: Markov Chains&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/03/moments%20and%20inequalities/"/>
    <id>http://yoursite.com/2018/02/03/moments and inequalities/</id>
    <published>2018-02-02T16:54:41.000Z</published>
    <updated>2018-02-02T17:01:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>title: Moments and Inequalities</p><a id="more"></a><h3 id="Moments-of-random-variables"><a href="#Moments-of-random-variables" class="headerlink" title="Moments of random variables"></a>Moments of random variables</h3><p>$k$-th moment: $E[X^k]$</p><h4 id="Moment-generation-functions"><a href="#Moment-generation-functions" class="headerlink" title="Moment generation functions"></a>Moment generation functions</h4><p>$M<em>X(t)\triangleq \sum</em>{x} e^{tx} Pr(X=x)=E[e^{tX}]$</p><h4 id="Markov’s-Inequality"><a href="#Markov’s-Inequality" class="headerlink" title="Markov’s Inequality"></a>Markov’s Inequality</h4><p>If $X\geq 0$ and $a&gt;0$, $Pr(X\geq a) \leq \frac{E[X]}{a}$.</p><h4 id="Chebyshev’s-Inequality"><a href="#Chebyshev’s-Inequality" class="headerlink" title="Chebyshev’s Inequality"></a>Chebyshev’s Inequality</h4><p>$Pr(|X-E[X]|\geq a) \leq \frac{Var[X]}{a^2}$.</p><h4 id="Chernoff-bounds"><a href="#Chernoff-bounds" class="headerlink" title="Chernoff bounds"></a>Chernoff bounds</h4><p>Let $X=\sum_{i=1}^n X_i$, where $X_i$’s are independent Poisson trials. Let $\mu=E[X]$. Then</p><ol><li><p>For any $\delta &gt; 0$, $Pr(X\geq (1+\delta)\mu) \leq \left(\frac{e^{\delta}}{(1+\delta)^{(1+\delta)}}\right)^{\mu}$</p></li><li><p>For any  $1&gt;\delta &gt; 0$, $Pr(X\leq (1-\delta)\mu) \leq \left(\frac{e^{-\delta}}{(1-\delta)^{(1-\delta)}}\right)^{\mu}$</p><p>​</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;title: Moments and Inequalities&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/03/elementary%20probability%20theory/"/>
    <id>http://yoursite.com/2018/02/03/elementary probability theory/</id>
    <published>2018-02-02T16:54:40.000Z</published>
    <updated>2018-02-02T17:00:44.000Z</updated>
    
    <content type="html"><![CDATA[<p>title: Elementary Probability Theory</p><a id="more"></a><h4 id="union-bound"><a href="#union-bound" class="headerlink" title="union bound"></a>union bound</h4><p>$$<br>Pr(\cup_{i\geq1}E<em>i) \leq \sum</em>{i\geq1}Pr(E_i)<br>$$</p><h4 id="Law-of-total-probability"><a href="#Law-of-total-probability" class="headerlink" title="Law of total probability"></a>Law of total probability</h4><p>If $E_1, E_2, \dots E<em>n$ are mutually disjoint and $\cup</em>{i=1}^nE<em>i=\Omega$, then $Pr(B)=\sum</em>{i=1}^nPr(B\cap E<em>i)=\sum</em>{i=1}^n Pr(B|E_i)Pr(E_i)$.</p><h4 id="Bayes’-Law"><a href="#Bayes’-Law" class="headerlink" title="Bayes’ Law"></a>Bayes’ Law</h4><p>If $E_1, E_2, \dots E<em>n$ are mutually disjoint and $\cup</em>{i=1}^nE_i=\Omega$, then $Pr(E_j|B)=\frac{Pr(B|E_j)Pr(E_j)}{Pr(B)}=\frac{Pr(B|E_j)Pr(E<em>j)}{\sum</em>{i=1}^n Pr(B|E_i)Pr(E_i)}$.</p><h4 id="Expectation"><a href="#Expectation" class="headerlink" title="Expectation"></a>Expectation</h4><ul><li><p>Linearity of expectation<br>$$<br>E[\sum_{i=1}^na_iX<em>i]=\sum</em>{i=1}^n a_iE[X_i]<br>$$</p></li><li><p>product counterpart</p><p>$E[X* Y]=E[X]E[Y] $ if they are independent​​</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;title: Elementary Probability Theory&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/03/fundamental%20laws/"/>
    <id>http://yoursite.com/2018/02/03/fundamental laws/</id>
    <published>2018-02-02T16:54:40.000Z</published>
    <updated>2018-02-02T17:00:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>title: Fundamental Laws of Probability Theory</p><a id="more"></a><h4 id="Law-of-Large-Numbers"><a href="#Law-of-Large-Numbers" class="headerlink" title="Law of Large Numbers"></a>Law of Large Numbers</h4><p>The sample average converges to the expected value.</p><h4 id="Central-Limit-Theorem"><a href="#Central-Limit-Theorem" class="headerlink" title="Central Limit Theorem"></a>Central Limit Theorem</h4><p>The arithmetic mean of independent random variables is approximately normally distributed.</p><h4 id="Large-Deviation-Principle"><a href="#Large-Deviation-Principle" class="headerlink" title="Large Deviation Principle"></a>Large Deviation Principle</h4><p>Let $X_1, \dots, X_n, \dots \in R$ be i.i.d, r.v. which satisfy $E[e^{tX_1}]&lt;\infty$ for $t\in R$. Then for any $t&gt;E[X<em>1]$, we have<br>$$<br>\lim</em>{n\to \infty}\frac{1}{n}\ln Pr(\sum_{i=1}^nX<em>i \geq tn) = -I(t)<br>$$<br>where<br>$$<br>I(t) \triangleq \sup</em>{\lambda&gt;0} \lambda t - \ln E[e^{\lambda X_1}]<br>$$</p><h4 id="Law-of-large-number-in-Markov-chains"><a href="#Law-of-large-number-in-Markov-chains" class="headerlink" title="Law of large number in Markov chains"></a>Law of large number in Markov chains</h4><p>Assume Markov chain $\left{ X_n \right}$ has a positive recurrent state $a$, $Pr(a \text{ is reached}| X<em>0=1)$, and $f: S \to R$  is bounded. Then<br>$$<br>Pr\left(\lim</em>{t \to \infty} \frac{f(X_0) + \dots + f(X<em>t)}{t}=\bar{f}\right)=1<br>$$<br>where<br>$$<br>\bar{f}=\frac{E[\sum</em>{n=0}^{T_{aa}-1}f(X<em>n)]}{E[T</em>{aa}]}=E_{\pi}[f]<br>$$</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;title: Fundamental Laws of Probability Theory&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>TranH</title>
    <link href="http://yoursite.com/2018/01/30/TransH/"/>
    <id>http://yoursite.com/2018/01/30/TransH/</id>
    <published>2018-01-30T12:12:44.000Z</published>
    <updated>2018-01-30T17:35:44.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>TransE - the cornerstone of translation approaches</title>
    <link href="http://yoursite.com/2018/01/30/TransE/"/>
    <id>http://yoursite.com/2018/01/30/TransE/</id>
    <published>2018-01-30T07:31:35.000Z</published>
    <updated>2018-01-30T17:53:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>TransE model proposed by Bordes et al. 提出了今后一系列translation方法的根基：</p><p>The functional relation induced by the $r$-labeled edges corresponds to a translation of the embeddings, i.e. $h + r \approx t$ when $(h, r, t)$ holds.</p><a id="more"></a><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>In TransE, relationships are represented as translations in the embedding space:</p><p>if $(h, r, t)$ holds, then the embedding of the tail entity $t$ should be close to the embedding of the head entity $h$ plus some vector that depends on the relationship $r$, which is<br>$$<br>h + r \approx t<br>$$<br>TransE maps all the entities and relations into the same embedding space, and learns only one low-dimensional vector for each of them.</p><h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><p>The functional relation induced by the $r$-labeled edges corresponds to a translation of the embeddings, i.e. $h + r \approx t$ when $(h, r, t)$ holds, while $h+r$ should be far away from $t$ otherwise.</p><p>The <strong>energy</strong> of a triplet is set to be $d(h+r, t)$ for some dissimilarity measure $d$, which is $L_1$ or $L_2$-norm.</p><p>Following an energy-based framework, the <strong>goal</strong> of TransE is to minimize a margin-based ranking criterion over the training set:<br>$$<br>L=\sum<em>{(h,r,t)\in S}\sum</em>{(h’,r,t’)\in S’<em>{(h,r,t)}}[\gamma + d(h+r, t) - d(h’+r, t’)]</em>{+}<br>$$<br>where $[x]<em>{+}$ denotes the positive part of $x$, which can also be denoted as $max(0, x)$. This can force $x$ to try to be as near $0$ as possible. $\gamma&gt;0$ is a margin hyperparameter, $S’$ is the set of corrupted triplets, constructed by replacing either head or tail entity by a random one:<br>$$<br>S’</em>{(h, r, t)} = \left{(h’, r, t) | h’ \in E \right} \cup \left{(h, r, t’)|t’\in E \right}<br>$$<br>The optimization is carried out by <strong>SGD</strong>, and the <strong>additional constraints</strong> that the $L_2$-norm of the embeddings of the entities is $1$, while no regularization or norm constraints are given to the label embeddings $r$. </p><p>The algorithm is stopped based on its performance on a validation set.</p><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>TransE can be implemented according to the algorithm:</p><p><img src="TransEAlg.png" alt="alg"></p><p>Note:</p><ul><li>relation $r$ is denoted as $l$ in the above algorithm</li><li>$l$ is normalized in the initialization stage, while the embedding vectors of the entities are first normalized at each main iteration</li><li>For each triplet in minibatch, sample a single corrupted triplet from $S’$. Golden triplets and corrupted triplets together consist triplet batch</li><li>Train to minimize $L$</li><li>$[x]_{+}$ is implemented by $max(0, x)$</li></ul><p>My implementation of TransE in tensorflow can be found on:</p><p><a href="http://baidu.com" target="_blank" rel="noopener">TransE implementation in tensorflow</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;TransE model proposed by Bordes et al. 提出了今后一系列translation方法的根基：&lt;/p&gt;
&lt;p&gt;The functional relation induced by the $r$-labeled edges corresponds to a translation of the embeddings, i.e. $h + r \approx t$ when $(h, r, t)$ holds.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
